# MetaGPT.TS

> A TypeScript-based multi-agent collaboration framework that transforms large language models into efficient agents, building a collaborative software development team.


## ğŸ“– æ–‡æ¡£ | Documentation

**[ä¸­æ–‡æ–‡æ¡£](README-CN.md)** | [English](README.md)

## Introduction

MetaGPT.TS is a modern TypeScript framework for building multi-agent systems. It transforms large language models (LLMs) into efficient agents that can collaborate as a software development team.

### Key Features
- **Agent Collaboration**: Built-in roles like Product Manager, Architect, and Engineer collaborate through standardized processes to complete complex tasks
- **End-to-End Support**: Intelligent support for the entire process from requirement analysis and system design to code implementation
- **High-Performance Architecture**: Based on modern TypeScript stack, providing efficient and type-safe development experience
- **Extensibility**: Support for custom roles, actions, and workflows to adapt to different application scenarios

## Quick Start

```bash
# Install with bun
bun install @louloulinx/metagpt

# Or with npm
npm install @louloulinx/metagpt
```

### Basic Configuration

```typescript
// Configure LLM provider
import { config } from "@louloulinx/metagpt";

config.OPENAI_API_KEY = "sk-..."; // Your API key
```

### Simple Example

```typescript
import { Team, ProductManager, Architect, Engineer } from "@louloulinx/metagpt";

// Create a team
const team = new Team();
team.hire([new ProductManager(), new Architect(), new Engineer()]);

// Execute project
await team.runProject("Implement a simple todo management application");
```

## Core Concepts

- **Role**: Task execution units with specific skills (Product Manager/Architect/Engineer)
- **Action**: Atomic operation units of agents
- **Team**: Organization of multiple roles working together
- **Memory**: Long-term memory storage with vector retrieval support

## Application Scenarios

- Agent-assisted development
- Automated workflow orchestration
- Complex task decomposition and execution
- AI team simulation and optimization
- Enterprise application intelligence transformation

## Core Features

1. **Multi-Role Collaboration** - Pre-configured roles including Product Manager, Architect, Engineer, etc.
2. **Automated Workflow** - Support for the entire process from requirement analysis to system design and code implementation
3. **Type Safety** - Strict TypeScript type checking
4. **Reactive Architecture** - Message pipeline processing based on RxJS
5. **Observability** - Built-in comprehensive logging and monitoring support

## Supported Models

| Provider  | Supported Versions     | Config Name        |
|-----------|------------------------|-------------------|
| OpenAI    | gpt-4/gpt-3.5-turbo    | OPENAI_API_KEY    |
| Anthropic | Claude-2               | ANTHROPIC_API_KEY |
| Azure     | GPT-4                  | AZURE_API_KEY     |

## Project Structure

```
metagpt/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ actions/      # Action definitions and implementations
â”‚   â”œâ”€â”€ roles/        # Role definitions and behaviors
â”‚   â”œâ”€â”€ utils/        # Utility functions and helper classes
â”‚   â”œâ”€â”€ config/       # Configuration management
â”‚   â”œâ”€â”€ memory/       # Memory and state management
â”‚   â”œâ”€â”€ provider/     # LLM provider integration
â”‚   â”œâ”€â”€ tools/        # External tool integration
â”‚   â”œâ”€â”€ skills/       # Skill implementations
â”‚   â”œâ”€â”€ rag/          # Retrieval-augmented generation
â”‚   â”œâ”€â”€ document/     # Document processing and management
â”‚   â””â”€â”€ types/        # TypeScript type definitions
â”œâ”€â”€ tests/            # Test files
â”œâ”€â”€ examples/         # Example implementations
â””â”€â”€ package.json      # Project dependencies and scripts
```

## Environment Configuration

MetaGPT.TS supports environment variable configuration through `.env` files for easy management of API keys and other configuration items.

1. Create a `.env` file in the project root directory:

```
# LLM provider configuration
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_API_MODEL=gpt-4-turbo
OPENAI_API_BASE=https://api.openai.com/v1

# Optional other LLM providers
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
AZURE_API_KEY=your-azure-api-key
AZURE_API_BASE=your-azure-endpoint

# Vector storage configuration
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your-qdrant-api-key

# Logging configuration
LOG_LEVEL=info # debug, info, warn, error

# Application settings
MAX_TOKENS=4000
TEMPERATURE=0.7
PROJECT_ROOT=./workspace
```

2. Or configure directly in code (not recommended):

```typescript
// Configure LLM provider (OpenAI example)
import { config } from "@louloulinx/metagpt";

config.OPENAI_API_KEY = "sk-..."; // Your API key
config.OPENAI_API_MODEL = "gpt-4-1106-preview"; // Model version
```

## Tutorial Assistant Example

The Tutorial Assistant is a specialized role that can generate comprehensive tutorial documents in Markdown format.

```typescript
import { VercelLLMProvider } from '@louloulinx/metagpt';
import { TutorialAssistant } from '@louloulinx/metagpt';
import { v4 as uuidv4 } from 'uuid';

/**
 * æ•™ç¨‹åŠ©æ‰‹ç¤ºä¾‹
 * 
 * è¯¥ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ•™ç¨‹åŠ©æ‰‹ç”ŸæˆMarkdownæ ¼å¼çš„æ•™ç¨‹æ–‡æ¡£
 */
async function main() {
  console.log(`ğŸš€ å¼€å§‹æ‰§è¡Œæ•™ç¨‹ç”Ÿæˆ [${new Date().toISOString()}]`);
  
  try {
    // ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    const apiKey = process.env.DASHSCOPE_API_KEY;
    console.log('âœ“ æ£€æŸ¥ç¯å¢ƒå˜é‡');
    
    if (!apiKey) {
      console.error('âŒ é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡: DASHSCOPE_API_KEY');
      process.exit(1);
    }
    console.log('âœ“ ç¯å¢ƒå˜é‡å·²è®¾ç½®');
    
    // åˆå§‹åŒ–Vercel LLMæä¾›å•† - ä½¿ç”¨ç™¾ç‚¼å¤§æ¨¡å‹(qwen)
    console.log('âš™ï¸ é…ç½®ç™¾ç‚¼å¤§æ¨¡å‹...');
    const llmProvider = new VercelLLMProvider({
      providerType: 'qwen',
      apiKey,
      model: 'qwen-plus-2025-01-25',
      baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1', // è‡ªå®šä¹‰APIç«¯ç‚¹
      extraConfig: {
        qwenOptions: {
          debug: true, // å¯ç”¨è°ƒè¯•æ—¥å¿—
        },
        generateOptions: {
          system: 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™ç¨‹ç¼–å†™ä¸“å®¶ï¼Œæ“…é•¿ç”Ÿæˆé«˜è´¨é‡ã€ç»“æ„æ¸…æ™°çš„æ•™ç¨‹æ–‡æ¡£ã€‚'
        }
      }
    });
    console.log(`âœ“ æ¨¡å‹é…ç½®å®Œæˆ: ${llmProvider.config?.providerType} - ${llmProvider.config?.model}`);
    
    console.log('âš™ï¸ åˆå§‹åŒ–æ•™ç¨‹åŠ©æ‰‹...');
    console.time('æ•™ç¨‹åŠ©æ‰‹åˆå§‹åŒ–æ—¶é—´');
    
    // åˆ›å»ºæ•™ç¨‹åŠ©æ‰‹
    const tutorialAssistant = new TutorialAssistant({
      llm: llmProvider,
      language: 'Chinese', // å¯é€‰: 'English'
      outputDir: './output/tutorials', // å¯é€‰ï¼Œé»˜è®¤ä¸º './tutorials'
    });
    
    console.timeEnd('æ•™ç¨‹åŠ©æ‰‹åˆå§‹åŒ–æ—¶é—´');
    console.log('âœ“ æ•™ç¨‹åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ');
    
    // è®¾ç½®è¦ç”Ÿæˆçš„æ•™ç¨‹ä¸»é¢˜
    const topic = 'è¥¿æ–¹ç»æµå­¦è€ƒç ”å¤è¯•èµ„æ–™';
    console.log(`ğŸ“ ç”Ÿæˆä¸»é¢˜: "${topic}"`);
    
    // ç”Ÿæˆæ•™ç¨‹
    console.log('ğŸ”„ å¼€å§‹ç”Ÿæˆæ•™ç¨‹...');
    console.log('ğŸ‘‰ æ­¥éª¤ 1: ç”Ÿæˆç›®å½•ç»“æ„');
    console.time('æ•™ç¨‹ç”Ÿæˆæ€»æ—¶é—´');
    
    const result = await tutorialAssistant.react({
      id: uuidv4(),
      role: 'user',
      content: topic,
      sentFrom: 'user',
      sendTo: new Set(['*']),
      instructContent: null,
    });
    
    console.timeEnd('æ•™ç¨‹ç”Ÿæˆæ€»æ—¶é—´');
    console.log('âœ… æ•™ç¨‹ç”Ÿæˆå®Œæˆ!');
    
    // æå–æ–‡ä»¶è·¯å¾„ï¼ˆå‡è®¾ç»“æœæ¶ˆæ¯ä¸­åŒ…å«æ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼‰
    const filePath = result.content.includes('saved to') 
      ? result.content.split('saved to ')[1].trim()
      : 'æœªæ‰¾åˆ°æ–‡ä»¶è·¯å¾„';
    
    console.log(`ğŸ“„ ç”Ÿæˆç»“æœ: ${result.content}`);
    console.log(`ğŸ“‚ è¾“å‡ºæ–‡ä»¶: ${filePath}`);
    console.log(`ğŸ æ•™ç¨‹ç”Ÿæˆå®Œæˆ [${new Date().toISOString()}]`);
  } catch (error) {
    console.error('âŒ ç”Ÿæˆæ•™ç¨‹æ—¶å‡ºé”™:', error);
    if (error instanceof Error) {
      console.error(`é”™è¯¯ç±»å‹: ${error.name}`);
      console.error(`é”™è¯¯ä¿¡æ¯: ${error.message}`);
      console.error(`é”™è¯¯å †æ ˆ: ${error.stack}`);
    }
  }
}

// è¿è¡Œç¤ºä¾‹
console.log('ğŸ“Œ æ•™ç¨‹åŠ©æ‰‹ç¤ºä¾‹');
main(); 
```



## Basic Usage Example (Coming Soon)

```typescript
import { Team, ProductManager, Architect, Engineer } from "@louloulinx/metagpt/roles";
import { Message } from "@louloulinx/metagpt";

async function startup(idea: string) {
  // Initialize team
  const company = new Team();
  
  // Build team
  company.hire([
    new ProductManager(),
    new Architect(),
    new Engineer(),
  ]);

  // Set initial parameters
  company.invest(3.0); // Set budget (virtual currency)
  
  // Run project
  const messages: Message[] = await company.runProject(
    idea,
    { maxRounds: 5 }
  );

  return messages;
}

// Execute example
await startup("Implement a command-line Reversi game");
```

## Technical Stack

### Core Technology Stack
1. Runtime & Package Manager
   - Bun.js: High-performance JavaScript runtime with built-in package manager
   - Node.js 18+ compatibility support

2. Development Language and Framework
   - TypeScript 5.0+: Strong type support
   - Zod: Runtime type validation
   - XState: State machine management
   - RxJS: Reactive programming

3. Testing and Development Tools
   - bun:test: Unit testing framework
   - ESLint + Prettier: Code standards
   - TypeDoc: API documentation generation

4. Core Dependencies
   - Vercel AI SDK
   - Qdrant Node Client: Vector storage
   - Winston: Log management

## Roadmap

### Core Architecture Evolution
1. Strengthen Type System
   - Implement runtime type validation
   - Enhance generic support
   - Improve pattern matching mechanism

2. Performance Optimization
   - Message pipeline performance benchmarking
   - Memory management optimization
   - Asynchronous task scheduling improvements

3. Extensibility Enhancement
   - Modular architecture refactoring
   - Dynamic plugin loading mechanism
   - Hot update support

### Ecosystem Building
1. Developer Toolchain
   - CLI tool enhancement
   - Visual debugger
   - Performance analysis tools

2. Templates and Examples
   - Create common scenario templates
   - Add enterprise-level examples
   - Build example library

3. Integration Support
   - Mainstream frontend framework adaptation
   - Node.js runtime optimization
   - Deno/Bun deep integration

## Acknowledgements

The design of metagpt.ts references the implementation logic of [MetaGPT](https://github.com/geekan/MetaGPT), for which we are grateful.


